{% include "components/utils_libraries.jinja"%}

{% include "components/metrics.py.jinja"%}


# TRAINING FUNCTIONS

def cross_val(classifier, data, label, unpriv_group, priv_group, sensitive_features, positive_label, metrics, n_splits=10, preprocessor=None, inprocessor=None, postprocessor=None):
    {%if not validation%}
    n_splits = 2
    {%endif%}
    fold = KFold(n_splits=n_splits, shuffle=True, random_state=2)
    for train, test in fold.split(data):
        weights = None
        data = data.copy()
        df_train = data.iloc[train]
        df_test = data.iloc[test]
        model = deepcopy(classifier)
        {%if reweighing%}
        if preprocessor == 'rw':
            prot_attr = [df_train[s] for s in sensitive_features]
            rw = Reweighing(prot_attr)
            x, weights = rw.fit_transform(df_train.drop(label, axis=1), df_train[label])
        {%endif%}
        {%if dir%}
        if preprocessor == 'dir':
            bin_data = BinaryLabelDataset(favorable_label=positive_label, 
                unfavorable_label=1-positive_label, 
                df=df_train, 
                label_names=[label], 
                protected_attribute_names=sensitive_features)
            dir = DisparateImpactRemover(sensitive_attribute=sensitive_features[0])
            trans_data = dir.fit_transform(bin_data)
            df_train, _ = trans_data.convert_to_dataframe()
        {%endif%}
        {%if lfr%}
        if preprocessor == 'lfr':
            bin_data = BinaryLabelDataset(favorable_label=positive_label, 
                unfavorable_label=1-positive_label, 
                df=df_train, 
                label_names=[label], 
                protected_attribute_names=sensitive_features)
            lfr = LFR(unprivileged_groups=[unpriv_group], privileged_groups=[priv_group])
            bin_data_fair = lfr.fit_transform(bin_data)
            df_train, _ = bin_data_fair.convert_to_dataframe()
        {%endif%}
        {%if demv or sampling%}
        if preprocessor == 'demv':
            demv = DEMV(round_level=1)
            df_train = demv.fit_transform(df_train, [keys for keys in unpriv_group.keys()], label)
        {%endif%}
        {%if exponentiated_gradient%}
        if inprocessor == 'eg':
            constr = _get_constr(df_train, label)
            model = ExponentiatedGradient(
                model, constraints=constr, sample_weight_name={{'"classifier__sample_weight"' if scaler else '"sample_weight"'}})
        {%endif%}
        {%if grid_search%}
        if inprocessor == 'grid':
            constr = _get_constr(df_train, label)
            model = GridSearch(
            model, constr, sample_weight_name={{'"classifier__sample_weight"' if scaler else '"sample_weight"'}})
        {%endif%}
        exp = bool(inprocessor == 'eg' or inprocessor == 'grid')
        pred = _model_train(df_train, df_test, label, model, sensitive_features, exp=exp, weights=weights)
        {%if blackbox%}
        if postprocessor=='blackbox':
            pred = blackbox(pred, label, sensitive_features, len(pred[label].unique())==2)
        {%endif%}
        compute_metrics(pred, unpriv_group, label, positive_label, metrics, sensitive_features)
    return model, metrics

{%if exponentiated_gradient or grid_search%}
def _get_constr(df, label):
    if len(df[label].unique()) == 2:
        constr = DemographicParity()
    else:
        constr = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)
    return constr
{%endif%}

def _train_test_split(df_train, df_test, label):
    x_train = df_train.drop(label, axis=1).values
    y_train = df_train[label].values.ravel()
    x_test = df_test.drop(label, axis=1).values
    y_test = df_test[label].values.ravel()
    return x_train, x_test, y_train, y_test


def _model_train(df_train, df_test, label, classifier, sensitive_features, exp=False, weights=None):
    x_train, x_test, y_train, y_test = _train_test_split(
        df_train, df_test, label)
    model = deepcopy(classifier)
    model.fit(x_train, y_train,
              sensitive_features=df_train[sensitive_features]) if exp else {{"model.fit(x_train, y_train, classifier__sample_weight=weights)" if scaler else  "model.fit(x_train, y_train, sample_weight=weights)"}}
    pred = model.predict(x_test)
    df_pred = df_test.copy()
    df_pred['y_true'] = df_pred[label]
    df_pred[label] = pred
    return df_pred


def compute_metrics(df_pred, unpriv_group, label, positive_label, metrics, sensitive_features):
{%if statistical_parity%}
    stat_par = statistical_parity(
        df_pred, unpriv_group, label, positive_label)
    metrics['stat_par'].append(stat_par)
{%endif%}
{%if equalized_odds%}
    eo = equalized_odds(
        df_pred, unpriv_group, label, positive_label)
    metrics['eq_odds'].append(eo)
{%endif%}
{%if disparate_impact%}
    di = disparate_impact(
        df_pred, unpriv_group, label, positive_label=positive_label)
    metrics['disp_imp'].append(di)
{%endif%}
{%if zero_one_loss%}
    zero_one_loss = zero_one_loss_diff(
        y_true=df_pred['y_true'].values, y_pred=df_pred[label].values, sensitive_features=df_pred[sensitive_features].values)
    metrics['zero_one_loss'].append(zero_one_loss)
{%endif%}
{%if accuracy%}
    accuracy = accuracy_score(df_pred['y_true'].values, df_pred[label].values)
    metrics['acc'].append(accuracy)
{%endif%}
{%if harmonic_mean%}
    metrics['hmean'].append(
        stats.hmean([
            {%if accuracy%}
            accuracy,
            {%endif%} 
            {%if disparate_impact%}
            di,
            {%endif%} 
            {%if equalized_odds%}
            norm_data(eo), 
            {%endif%}
            {%if statistical_parity%}
            norm_data(stat_par), 
            {%endif%}
            {%if zero_one_loss%}
            norm_data(zero_one_loss)
            {%endif%}
        ])
    )
{%endif%}
    return metrics

{%if blackbox%}
def blackbox(pred, label, sensitive_var, binary=True):
    pb = BinaryBalancer(y='y_true', y_=label, a=sensitive_var, data=pred) if binary else \
        MulticlassBalancer(y='y_true', y_=label, a=sensitive_var, data=pred)
    y_adj = pb.adjust(cv=True, summary=False)
    pred[label] = y_adj

    return pred
{%endif%}